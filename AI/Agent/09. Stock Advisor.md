<br />

## yfinance

Yahoo Finance(야후 파이낸스)에서 주식/ETF/지수 등의 금융 데이터를 가져올 수 있도록 도와주는 파이썬 라이브러리

<br />

- 설치

```python
pip install yfinance
```

<br />

- Ticker 생성

```python
import yfinance as yf

# Microsoft (MSFT)에 대한 Ticker 객체 생성
msft = yf.Ticker("MSFT")
display(msft.info)
```

```json
{'address1': 'One Microsoft Way',
 'city': 'Redmond',
 'state': 'WA',
 'zip': '98052-6399',
 'country': 'United States',
 'phone': '425 882 8080',
 'website': 'https://www.microsoft.com',
 'industry': 'Software - Infrastructure',
 'industryKey': 'software-infrastructure',
 'industryDisp': 'Software - Infrastructure',
 'sector': 'Technology',
 'sectorKey': 'technology',
 'sectorDisp': 'Technology',
 'longBusinessSummary': 'Microsoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services. This segment also provides LinkedIn; and dynamics business solutions, including Dynamics 365, a set of intelligent, cloud-based applications across ERP, CRM, power apps, and power automate; and on-premises ERP and CRM applications. The Intelligent Cloud segment offers server products and cloud services, such as azure and other cloud services; SQL and windows server, visual studio, system center, and related client access licenses, as well as nuance and GitHub; and enterprise services including enterprise support services, industry solutions, and nuance professional services. The More Personal Computing segment offers Windows, including windows OEM licensing and other non-volume licensing of the Windows operating system; Windows commercial comprising volume licensing of the Windows operating system, windows cloud services, and other Windows commercial offerings; patent licensing; and windows Internet of Things; and devices, such as surface, HoloLens, and PC accessories. Additionally, this segment provides gaming, which includes Xbox hardware and content, and first- and third-party content; Xbox game pass and other subscriptions, cloud gaming, advertising, third-party disc royalties, and other cloud services; and search and news advertising, which includes Bing, Microsoft News and Edge, and third-party affiliates. The company sells its products through OEMs, distributors, and resellers; and directly through digital marketplaces, online, and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.',
 'fullTimeEmployees': 228000,
 'companyOfficers': [{'maxAge': 1,
   'name': 'Mr. Satya  Nadella',
   'age': 57,
   'title': 'Chairman & CEO',
   'yearBorn': 1967,
   'fiscalYear': 2024,
   'totalPay': 7869791,
   'exercisedValue': 0,
   'unexercisedValue': 0},
  {'maxAge': 1,
...
 'esgPopulated': False,
 'shortName': 'Microsoft Corporation',
 'longName': 'Microsoft Corporation',
 'displayName': 'Microsoft',
 'trailingPegRatio': 2.2524}
```

<br />

- 주가 데이터 가져오기

```python
hist = msft.history(period="5d") # 5일간의 주가 데이터를 가져옴
display(hist)
```

| **Open**                  | **High**   | **Low**    | **Close**  | **Volume** | **Dividends** | **Stock Splits** |
| ------------------------- | ---------- | ---------- | ---------- | ---------- | ------------- | ---------------- |
| **Date**                  |            |            |            |            |               |                  |
| 2025-06-12 00:00:00-04:00 | 475.019989 | 480.420013 | 473.519989 | 478.869995 | 18950600      | 0.0              |
| 2025-06-13 00:00:00-04:00 | 476.410004 | 479.179993 | 472.760010 | 474.959991 | 16814500      | 0.0              |
| 2025-06-16 00:00:00-04:00 | 475.209991 | 480.690002 | 475.000000 | 479.140015 | 15626100      | 0.0              |
| 2025-06-17 00:00:00-04:00 | 475.399994 | 478.739990 | 474.079987 | 478.040009 | 15414100      | 0.0              |
| 2025-06-18 00:00:00-04:00 | 478.000000 | 481.000000 | 474.459991 | 480.239990 | 17526500      | 0.0              |

<br />

- 추천 정보

```python
msft.recommendations
```

|     | **period** | **strongBuy** | **buy** | **hold** | **sell** | **strongSell** |
| --- | ---------- | ------------- | ------- | -------- | -------- | -------------- |
| 0   | 0m         | 14            | 40      | 6        | 0        | 0              |
| 1   | -1m        | 15            | 41      | 5        | 0        | 0              |
| 2   | -2m        | 14            | 41      | 6        | 0        | 0              |
| 3   | -3m        | 15            | 41      | 6        | 0        | 0              |

<br />

## Stock Advisor

Streamlit 웹 앱에서 OpenAI GPT-4o와 연동해 사용자 입력을 받고, 주식 정보 조회 등 다양한 도구를 활용하는 Stock Advisor 역할의 챗봇으로 AI 응답을 처리하고 출력하는 프로그램

<br />

- 설치

```python
pip install yfinance
pip install pytz
pip install streamlit
pip install tabulate
```

<br />

- 코드

```python
# script.py
from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
from openai import OpenAI
from dotenv import load_dotenv
import os
import json
import streamlit as st

env_path = "api_key.env"
load_dotenv(dotenv_path=env_path)

api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

st.title("💬 Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": "너는 사용자를 도와주는 상담사야."},  # 초기 시스템 메시지
    ]

for msg in st.session_state.messages:
    if msg["role"] == "assistant" or msg["role"] == "user": # assistant 혹은 user 메시지인 경우만
        st.chat_message(msg["role"]).write(msg["content"])

if user_input := st.chat_input():    # 사용자 입력 받기
    st.session_state.messages.append({"role": "user", "content": user_input})  # 사용자 메시지를 대화 기록에 추가
    st.chat_message("user").write(user_input)  # 사용자 메시지를 브라우저에서도 출력

    ai_response = client.chat.completions.create(
        model="gpt-4o",
        messages=st.session_state.messages,
        tools=tools,
    )
    ai_message = ai_response.choices[0].message

    tool_calls = ai_message.tool_calls  # AI 응답에 포함된 tool_calls를 가져옴
    if tool_calls: # tool_calls가 있는 경우
        for tool_call in tool_calls:
            tool_name = tool_call.function.name # 함수명
            tool_call_id = tool_call.id         # id
            arguments = json.loads(tool_call.function.arguments) # 문자열을 딕셔너리로 변환
            func_result = ""

            if tool_name == "get_current_time":
                func_result = get_current_time(timezone=arguments['timezone'])
            elif tool_name == "get_yf_stock_info":
                func_result = get_yf_stock_info(ticker=arguments['ticker'])
            elif tool_name == "get_yf_stock_history":
                func_result = get_yf_stock_history(
                    ticker=arguments['ticker'],
                    period=arguments['period']
                )
            elif tool_name == "get_yf_stock_recommendations":
                func_result = get_yf_stock_recommendations(ticker=arguments['ticker'])

            st.session_state.messages.append({
                "role": "function",
                "tool_call_id": tool_call_id,
                "name": tool_name,
                "content": func_result,
            })

        st.session_state.messages.append({"role": "system", "content": "이제 주어진 결과를 바탕으로 답변할 차례다."})
        ai_response = client.chat.completions.create(
            model="gpt-4o",
            messages=st.session_state.messages,
            tools=tools,
        ) # 다시 GPT 응답 받기
        ai_message = ai_response.choices[0].message

    st.session_state.messages.append({
        "role": "assistant",
        "content": ai_message.content
    })  # AI 응답을 대화 기록에 추가

    st.chat_message("assistant").write(ai_message.content)  # 브라우저에 메시지 출력
```

```python
# gpt_functions
from datetime import datetime
import pytz
import yfinance as yf

def get_current_time(timezone: str = 'Asia/Seoul'):
    tz = pytz.timezone(timezone) # 타임존 설정
    now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
    now_timezone = f'{now} {timezone}'
    return now_timezone

def get_yf_stock_info(ticker: str):
    stock = yf.Ticker(ticker)
    info = stock.info
    return str(info)

def get_yf_stock_history(ticker: str, period: str):
    stock = yf.Ticker(ticker)
    history = stock.history(period=period)
    history_md = history.to_markdown() # 데이터프레임을 마크다운 형식으로 변환
    return history_md

def get_yf_stock_recommendations(ticker: str):
    stock = yf.Ticker(ticker)
    recommendations = stock.recommendations
    recommendations_md = recommendations.to_markdown() # 데이터프레임을 마크다운 형식으로 변환
    return recommendations_md

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "해당 타임존의 날짜와 시간을 반환합니다.",
            "parameters": {
                "type": "object",
                "properties": {
                    'timezone': {
                        'type': 'string',
                        'description': '현재 날짜와 시간을 반환할 타임존을 입력하세요. (예: Asia/Seoul)',
                    },
                },
                "required": ['timezone'],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_yf_stock_info",
            "description": "해당 종목의 Yahoo Finance 정보를 반환합니다.",
            "parameters": {
                "type": "object",
                "properties": {
                    'ticker': {
                        'type': 'string',
                        'description': 'Yahoo Finance 정보를 반환할 종목의 티커를 입력하세요. (예: AAPL)',
                    },
                },
                "required": ['ticker'],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_yf_stock_history",
            "description": "해당 종목의 Yahoo Finance 주가 정보를 반환합니다.",
            "parameters": {
                "type": "object",
                "properties": {
                    'ticker': {
                        'type': 'string',
                        'description': 'Yahoo Finance 주가 정보를 반환할 종목의 티커를 입력하세요. (예: AAPL)',
                    },
                    'period': {
                        'type': 'string',
                        'description': '주가 정보를 조회할 기간을 입력하세요. (예: 1d, 5d, 1mo, 1y, 5y)',
                    },
                },
                "required": ['ticker', 'period'],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_yf_stock_recommendations",
            "description": "해당 종목의 Yahoo Finance 추천 정보를 반환합니다.",
            "parameters": {
                "type": "object",
                "properties": {
                    'ticker': {
                        'type': 'string',
                        'description': 'Yahoo Finance 추천 정보를 반환할 종목의 티커를 입력하세요. (예: AAPL)',
                    },
                },
                "required": ['ticker'],
            },
        }
    },
]
```

<br />

- 실행

```python
streamlit run script.py
```

<br />

<details>
  <summary>stream 출력하기</summary>

- 답변이 타이핑하듯이 출력되게 만들기 위해 코드를 다음과 같이 약간 수정하면 됨

```python
from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
from openai import OpenAI
from dotenv import load_dotenv
import os
import json
import streamlit as st
from collections import defaultdict

env_path = "api_key.env"
load_dotenv(dotenv_path=env_path)

api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def get_ai_response(messages, tools=None, stream=True):
    response = client.chat.completions.create(
        model="gpt-4o", # 응답 생성에 사용할 모델을 지정
        stream=stream, # 스트리밍 출력을 위해 설정
        messages=messages, # 대화 기록을 입력으로 전달
        tools=tools, # 사용 가능한 도구 목록을 전달
    )

    if stream:
        for chunk in response:
            yield chunk # 생성된 응답의 내용을 yield로 순차적으로 반환
    else:
        return response # 생성된 응답의 내용을 반환

def merge_tool_calls(tool_calls):
    # 기본 값을 가진 딕셔너리 초기화
    tool_calls_dict = defaultdict(lambda: {"id": None, "function": {"arguments": "", "name": None}, "type": None})

    # 도구(함수) 호출을 반복하여 처리
    for tool_call in tool_calls:
        # id가 None이 아닌 경우 설정
        if tool_call.id is not None:
            tool_calls_dict[tool_call.index]["id"] = tool_call.id

        # 함수 이름이 None이 아닌 경우 설정
        if tool_call.function.name is not None:
            tool_calls_dict[tool_call.index]["function"]["name"] = tool_call.function.name

        # 인수 추가
        tool_calls_dict[tool_call.index]["function"]["arguments"] += tool_call.function.arguments

        # 타입이 None이 아닌 경우 설정
        if tool_call.type is not None:
            tool_calls_dict[tool_call.index]["type"] = tool_call.type

    return list(tool_calls_dict.values()) # 딕셔너리를 리스트로 변환

st.title("💬 Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": "너는 사용자를 도와주는 상담사야."}, # 초기 시스템 메시지
    ]

for msg in st.session_state.messages:
    if msg["role"] == "assistant" or msg["role"] == "user": # assistant 혹은 user 메시지인 경우만
        st.chat_message(msg["role"]).write(msg["content"])

if user_input := st.chat_input(): # 사용자 입력 받기
    st.session_state.messages.append({"role": "user", "content": user_input}) # 사용자 메시지를 대화 기록에 추가
    st.chat_message("user").write(user_input) # 사용자 메시지를 브라우저에서도 출력

    ai_response = get_ai_response(st.session_state.messages, tools=tools)

    content = ''
    tool_calls = []

    first_chunk = next(ai_response) # 첫 번째 청크 추출
    content_first_chunk = first_chunk.choices[0].delta.content # 첫 번째 청크 속 content 추출
    tool_calls_first_chunk = first_chunk.choices[0].delta.tool_calls # 첫 번째 청크 속 tool calls 추출

    if content_first_chunk != None:
        with st.chat_message("assistant").empty(): # 스트림릿 챗 메시지 초기화

            content += content_first_chunk
            st.markdown(content)

            if tool_calls_first_chunk:
                tool_calls += tool_calls_first_chunk

            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content # 청크 속 content 추출
                tool_calls_chunk = chunk.choices[0].delta.tool_calls # 청크 속 tool calls 추출

                if content_chunk: # 만약 content_chunk가 있다면,
                    content += content_chunk # content에 덧붙이기
                    st.markdown(content) # 스트림릿 챗 메시지에 마크다운으로 출력

                if tool_calls_chunk: # tool_calls가 있는 경우
                    tool_calls += tool_calls_chunk # tool_calls_chunk에 추가

    elif content_first_chunk == None:
        if tool_calls_first_chunk:
            tool_calls += tool_calls_first_chunk

            for chunk in ai_response:
                tool_calls_chunk = chunk.choices[0].delta.tool_calls # 청크 속 tool calls 추출

                if tool_calls_chunk: # tool_calls가 있는 경우
                    tool_calls += tool_calls_chunk # tool_calls_chunk에 추가

    merged_tool_calls = merge_tool_calls(tool_calls)

    if merged_tool_calls: # tool_calls가 있는 경우
        for tool_call in merged_tool_calls:
            tool_name = tool_call["function"]["name"] # 함수명
            tool_call_id = tool_call["id"] # id
            arguments = json.loads(tool_call["function"]["arguments"]) # 문자열을 딕셔너리로 변환
            func_result = ""

            if tool_name == "get_current_time":
                func_result = get_current_time(timezone=arguments['timezone'])
            elif tool_name == "get_yf_stock_info":
                func_result = get_yf_stock_info(ticker=arguments['ticker'])
            elif tool_name == "get_yf_stock_history":
                func_result = get_yf_stock_history(
                    ticker=arguments['ticker'],
                    period=arguments['period']
                )
            elif tool_name == "get_yf_stock_recommendations":
                func_result = get_yf_stock_recommendations(ticker=arguments['ticker'])

            st.session_state.messages.append({
                "role": "function",
                "tool_call_id": tool_call_id,
                "name": tool_name,
                "content": func_result,
            })

        st.session_state.messages.append({"role": "system", "content": "이제 주어진 결과를 바탕으로 답변할 차례다."})
        ai_response = get_ai_response(st.session_state.messages, tools=tools) # 다시 GPT 응답 받기
        content = ""
        with st.chat_message("assistant").empty():
            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content
                if content_chunk:
                    content += content_chunk
                    st.markdown(content) # 스트림릿 챗메시지에 markdown으로 출력

    st.session_state.messages.append({
        "role": "assistant",
        "content": content
    })  # AI 응답을 대화 기록에 추가

```

<br />

- response (function call이 발생하지 않았을 때)

```python
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='안', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='녕하세요', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content=' 어떻게', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content=' 도', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='와', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='드', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='릴', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='까요', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1750407696, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
```

```json
ChatCompletionChunk(
		id='chatcmpl-BkRI8o4jKKINa8Mq4O7B4MrBnXVJ0',
		choices=[
				Choice(
						delta=ChoiceDelta(
								content='',
								function_call=None,
								refusal=None,
								role='assistant',
								tool_calls=None
						),
						finish_reason=None,
						index=0,
						logprobs=None
				)
		],
		created=1750407696,
		model='gpt-4o-2024-08-06',
		object='chat.completion.chunk',
		service_tier='default',
		system_fingerprint='fp_07871e2ad8',
		usage=None
)
```

<br />

- response (function call이 발생했을 때)

```python
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_eigdvC5kJ6AlZkfQ3rtgx9Ja', function=ChoiceDeltaToolCallFunction(arguments='', name='get_current_time'), type='function')]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='{"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='timezone', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='":"', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='Asia', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='/', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='Se', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='oul', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=[ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='"}', name=None), type=None)]), finish_reason=None, index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
ChatCompletionChunk(id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1750407962, model='gpt-4o-2024-08-06', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=None)
```

```json
ChatCompletionChunk(
		id='chatcmpl-BkRMQUSphC0WaTz7p8D6vxrhMZ9B4',
		choices=[
				Choice(
						delta=ChoiceDelta(
								content=None,
								function_call=None,
								refusal=None,
								role='assistant',
								tool_calls=[
										ChoiceDeltaToolCall(
												index=0,
												id='call_eigdvC5kJ6AlZkfQ3rtgx9Ja',
												function=ChoiceDeltaToolCallFunction(
														arguments='',
														name='get_current_time'
												),
												type='function'
										)
								]
						),
						finish_reason=None,
						index=0,
						logprobs=None
				)
		],
		created=1750407962,
		model='gpt-4o-2024-08-06',
		object='chat.completion.chunk',
		service_tier='default',
		system_fingerprint='fp_07871e2ad8',
		usage=None
)
```

</details>

<br />
<br />
<br />

[출처: 이성용, 「Do it! LLM을 활용한 AI 에이전트 개발 입문 - GPT API+딥시크+라마+랭체인+랭그래프+RAG」, 이지스퍼블리싱](https://www.easyspub.co.kr/20_Menu/BookView/764/PUB)

<br />
