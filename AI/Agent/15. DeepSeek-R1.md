<br />

## Download

[Ollama](https://ollama.com/download) 다운로드

<br />

## Excute

- 본인의 컴퓨터 사양에 맞게 모델을 선택하여 명령어를 복사해 [DeepSeek-R1](https://ollama.com/library/deepseek-r1)를 설치

```jsx
ollama run deepseek-r1:1.5b
```

<p></p>

- langchain_ollama를 설치

```jsx
pip install langchain_ollama
```

<p></p>

- DeepSeek-R1 모델 적용

```python
**from langchain_ollama import ChatOllama**
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

**llm = ChatOllama(model="deepseek-r1:1.5b")**

messages = [
    SystemMessage("너는 사용자를 도와주는 상담사야."),
]

while True:
    user_input = input("사용자: ")

    if user_input == "exit":
        break

    messages.append(
        HumanMessage(user_input)
    )

    response = llm.stream(messages)

    ai_message = None
    for chunk in response:
        print(chunk.content, end="")
        if ai_message is None:
            ai_message = chunk
        else:
            ai_message += chunk
    print('')

    message_only = ai_message.content.split("</think>")[1].strip()
    messages.append(AIMessage(message_only))

```

<br />
<br />
<br />

[출처: 이성용, 「Do it! LLM을 활용한 AI 에이전트 개발 입문 - GPT API+딥시크+라마+랭체인+랭그래프+RAG」, 이지스퍼블리싱](https://www.easyspub.co.kr/20_Menu/BookView/764/PUB)

<br />
